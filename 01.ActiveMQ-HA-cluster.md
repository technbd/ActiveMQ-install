## ActiveMQ Cluster:

A cluster consists of multiple broker instances that have been grouped together. Broker clusters enhance performance by distributing the message processing load across multiple brokers. In addition, broker clusters can minimize downtime through high availability. An ActiveMQ cluster allows you to make your messaging system highly available and scalable. 


**A cluster connects multiple brokers (ActiveMQ servers) so they can:**
- Share messages or load balance clients.
- Provide high availability (HA).
- Offer failover if one broker goes down.
- Scale horizontally by distributing message load.


### Types of ActiveMQ Clustering (Classic 5.x):

There are two main patterns:
| Type                                 | Description                                                                                                         |
| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------- |
| **Master-Slave (HA)**                | Only one broker (master) is active. If it fails, the slave takes over using the same storage.                       |
| **Network of Brokers (Scalability)** | Multiple brokers share messages via a network connection â€” clients can connect to any broker and still communicate. |





---
---





## Configure Masterâ€“Slave (High Availability) Broker:

This is a production-grade HA setup where two (or more) brokers share the same message store directory (via NFS, GlusterFS, or SAN). Only **one broker (Master)** runs at a time. If it fails, the **Slave** detects that the shared store is free, locks it, and automatically becomes the new Master.

ActiveMQ supports shared storage HA using file-based persistence. Both brokers share the same message store directory (e.g., NFS or SAN). This setup requires shared storage visible to both brokers.

```xml

<broker xmlns="http://activemq.apache.org/schema/core"
        brokerName="shared-broker"
        dataDirectory="/shared/activemq-data">
```

- Only one broker (master) locks the store.
- When it fails, the slave detects unlock and takes over.



### Requirements

Both nodes must:
- Run the same ActiveMQ version
- Use the same Java version
- Have identical configuration
- Share a common message store directory (mounted via NFS or SAN)



### Architecture Overview:

| Node                    | Hostname                               | IP              | Role |
| ----------------------- | -------------------------------------- | --------------- | ---- |
| broker1                 | 192.168.10.192                         | Master (Active) |      |
| broker2                 | 192.168.10.193                         | Slave (Standby) |      |
| `/shared/activemq-data` | Shared NFS directory (mounted on both) |                 |      |




### Configure Shared Storage:


#### NFS server:

```
mkdir -p /data/activemq-data

chown -R nobody:nogroup /data/activemq-data    # Debian/Ubuntu
chown -R nobody:nobody /data/activemq-data     # RHEL/CentOS/Rocky

chmod -R 775 /data/activemq-data
```



```
vim /etc/exports

/data/activemq-data  *(rw,sync,no_root_squash)
```



```
exportfs -avr

showmount -e 192.168.10.191
```


#### Mount Shared NFS Directory (On both `broker1` and `broker2`):

Mount the same NFS share on both brokers (example path: `/shared/activemq-data`).


```
mkdir -p /shared/activemq-data

chown -R activemq:activemq /shared/activemq-data

chmod -R 775 /shared/activemq-data
```



```
vim /etc/fstab

192.168.10.191:/data/activemq-data /shared/activemq-data nfs defaults 0 0
```


```
mount -a
```




### Configure ActiveMQ Broker:


| Setting                | broker1                          | broker2      | Notes                            |
| ---------------------- | -------------------------------- | ------------ | -------------------------------- |
| `dataDirectory`        | âœ… same (`/shared/activemq-data`) | âœ… same       | Must point to shared storage  |
| `brokerName`           | ðŸ”¸ different (recommended)        | ðŸ”¸ different | Helps distinguish logs only      |
| `<persistenceAdapter>` | âœ… same                           | âœ… same       | Same shared store (KahaDB)       |
| `transportConnector`   | âœ… same                           | âœ… same       | Listens on 0.0.0.0:61616         |
| Users/passwords        | âœ… same                           | âœ… same       | Must match                       |
| Java/home path         | âœ… same                           | âœ… same       | Ensure both run same JDK version |




#### On `broker1`:

_Edit Jetty file:_
```xml

vim conf/jetty.xml


<bean id="jettyPort" class="org.apache.activemq.web.WebConsolePort" init-method="start">
             <!-- the default port number for the web console -->
        <property name="host" value="0.0.0.0"/>
        <property name="port" value="8161"/>
    </bean>
```


_Edit the main configuration file and Replace the default `<broker>` section with:_
```xml

vim conf/activemq.xml


<!-- <broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost" dataDirectory="${activemq.data}"> -->
<!-- <broker xmlns="http://activemq.apache.org/schema/core" brokerName="broker1" dataDirectory="/shared/activemq-data"> -->
<broker xmlns="http://activemq.apache.org/schema/core" brokerName="broker1" dataDirectory="/shared/activemq-data" useJmx="true" schedulerSupport="true">


<!-- Optional: web admin console (default 8161) -->
        <managementContext>
            <managementContext createConnector="false"/>
        </managementContext>


<!-- Shared KahaDB Store -->
        <persistenceAdapter>
            <!-- <kahaDB directory="${activemq.data}/kahadb"/>  -->
            <kahaDB directory="/shared/activemq-data/kahadb"/>
        </persistenceAdapter>


<!-- Network connectors (clients connect here) -->
        <transportConnectors>
            <!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB -->
            <transportConnector name="openwire" uri="tcp://0.0.0.0:61616?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="amqp" uri="amqp://0.0.0.0:5672?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="stomp" uri="stomp://0.0.0.0:61613?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="mqtt" uri="mqtt://0.0.0.0:1883?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="ws" uri="ws://0.0.0.0:61614?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
        </transportConnectors>
    
</broker>
```


```
systemctl restart activemq
```



#### On `broker2`:

_Edit Jetty file:_
```xml

vim conf/jetty.xml


<bean id="jettyPort" class="org.apache.activemq.web.WebConsolePort" init-method="start">
             <!-- the default port number for the web console -->
        <property name="host" value="0.0.0.0"/>
        <property name="port" value="8161"/>
    </bean>
```



_Exactly the same, except the name:_
```xml

vim conf/activemq.xml


<!--  <broker xmlns="http://activemq.apache.org/schema/core" brokerName="localhost" dataDirectory="${activemq.data}"> -->
<broker xmlns="http://activemq.apache.org/schema/core" brokerName="broker2" dataDirectory="/shared/activemq-data" useJmx="true" schedulerSupport="true">


<!-- Optional: web admin console (default 8161) -->
        <managementContext>
            <managementContext createConnector="false"/>
        </managementContext>


<!-- Shared KahaDB Store -->
        <persistenceAdapter>
            <!-- <kahaDB directory="${activemq.data}/kahadb"/>  -->
            <kahaDB directory="/shared/activemq-data/kahadb"/>
        </persistenceAdapter>


<!-- Network connectors (clients connect here) -->
        <transportConnectors>
            <!-- DOS protection, limit concurrent connections to 1000 and frame size to 100MB -->
            <transportConnector name="openwire" uri="tcp://0.0.0.0:61616?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="amqp" uri="amqp://0.0.0.0:5672?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="stomp" uri="stomp://0.0.0.0:61613?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="mqtt" uri="mqtt://0.0.0.0:1883?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
            <transportConnector name="ws" uri="ws://0.0.0.0:61614?maximumConnections=1000&amp;wireFormat.maxFrameSize=104857600"/>
        </transportConnectors>
    
</broker>
```



```
systemctl restart activemq
```




### Web Console: 

Access via browser:` http://<broker-IP>:8161/admin`




### Load Balancer for Application on Port 61616 (Optional):

This is the JMS transport port (61616) â€” used by applications to connect. Clients connect to **HAProxy_IP:61616** like `tcp://192.168.10.100:61616`, and it will automatically route to the active broker. For seamless client connection, use **HAProxy** in front of both brokers:

```
frontend activemq_front
    bind *:61616
    mode tcp
    default_backend activemq_back

backend activemq_back
    balance first       # Always prefer the first available (master)
    mode tcp
    option tcp-check

    server broker1 192.168.10.192:61616 check inter 3s fall 3 rise 2
    server broker2 192.168.10.193:61616 check inter 3s fall 3 rise 2 backup
```



### Load Balancer for Web Console (Optional):

If you just want admin access to whichever broker is active:

```
frontend activemq_console
    bind *:80
    mode http
    default_backend activemq_console_back

backend activemq_console_back
    mode http
    balance first                # Always prefer the first available (master)

    server broker1 192.168.10.192:61616 check
    server broker2 192.168.10.193:61616 check backup
```





